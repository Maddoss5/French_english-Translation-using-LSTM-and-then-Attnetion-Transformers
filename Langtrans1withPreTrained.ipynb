{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fd3d8b-bef9-4182-9c47-04ed5b94f8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "#from torchvision import Datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d41ae3-f85b-4266-976e-115410421201",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "spacy_fr = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55619e2a-5124-4c0d-b365-a0268bffca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812e5bfb-6be0-4cf7-bd9a-838083f45a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('engfrench.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9de6cd-6070-4bb0-8a97-c5cfb6d3cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175621\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16df2aed-79f6-4a10-af85-e10d4a10a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    The guards found a hacksaw blade in the prison...\n",
       "French words/sentences     Les gardiens trouvèrent une lame de scie à mét...\n",
       "Name: 170000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[170000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "025efad2-8e80-47f1-a486-64a94073dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Be very careful.</td>\n",
       "      <td>Sois très prudente !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Bees make honey.</td>\n",
       "      <td>Les abeilles font du miel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Behave yourself.</td>\n",
       "      <td>Comporte-toi bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>Bite the bullet.</td>\n",
       "      <td>Serre les dents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>Bite the bullet.</td>\n",
       "      <td>Serrez les dents.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      English words/sentences      French words/sentences\n",
       "10000        Be very careful.        Sois très prudente !\n",
       "10001        Bees make honey.  Les abeilles font du miel.\n",
       "10002        Behave yourself.          Comporte-toi bien.\n",
       "10003        Bite the bullet.            Serre les dents.\n",
       "10004        Bite the bullet.           Serrez les dents."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10000:10005]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe24555-676c-440b-b2bd-4876a36cc782",
   "metadata": {},
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbe1ff5-c1f9-4b8b-aec0-a4e907ffceb4",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d31611e-192e-4b2a-bafb-06ca5a82ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN_ID=0\n",
    "SOS_TOKEN_ID = 1\n",
    "EOS_TOKEN_ID = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad1c64-dd2d-4601-b8f5-df4f66600163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ed24b-8349-4eb7-b1d3-bbc3e5a9aa54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf3179-1b66-40fb-adac-a22ca0fc5971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f06527-e676-4c98-962a-2c4f64ec51b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8165ff4-0c6a-443e-b3bc-7b9defd201fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txten=data.iloc[0,0]\n",
    "txtfr=data.iloc[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841c7d65-e445-45da-9b8c-605193c87e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36b3ef1e-ee68-42a6-add8-02108412f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salut!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b9abb0-f1ad-400b-934e-4c6c46c165ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_17304\\1505539583.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  en_check=torch.load('engEmbeddings.pt')\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_17304\\1505539583.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fr_check=torch.load('frEmbeddings.pt')\n"
     ]
    }
   ],
   "source": [
    "en_check=torch.load('engEmbeddings.pt')\n",
    "fr_check=torch.load('frEmbeddings.pt')\n",
    "en_weights=en_check['weights']\n",
    "en_vocab=en_check['vocab_dict']\n",
    "fr_weights=fr_check['weights']\n",
    "fr_vocab=fr_check['vocab_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dfb4c38-f5c7-4858-8734-f1ee732f9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataframe, en_vocab, fr_vocab):\n",
    "        self.df = dataframe\n",
    "        self.en_vocab = en_vocab\n",
    "        self.fr_vocab = fr_vocab\n",
    "        \n",
    "        # Define special token IDs\n",
    "        # IMPORTANT: Ensure these keys exist in your vocab dictionaries!\n",
    "        self.unk_idx_en = en_vocab.get('<unk>', 0) # Default to 0 if not found\n",
    "        self.eos_idx_en = en_vocab.get('<eos>', 2)\n",
    "        \n",
    "        self.unk_idx_fr = fr_vocab.get('<unk>', 0)\n",
    "        self.sos_idx_fr = fr_vocab.get('<sos>', 1)\n",
    "        self.eos_idx_fr = fr_vocab.get('<eos>', 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Get Raw Text\n",
    "        src_text = str(self.df.iloc[index, 0])\n",
    "        trg_text = str(self.df.iloc[index, 1])\n",
    "\n",
    "        # 2. Tokenize (using your Spacy functions)\n",
    "        # We use .lower() because FastText matches better with lowercase\n",
    "        src_tokens = tokenize_en(src_text.lower())\n",
    "        trg_tokens = tokenize_fr(trg_text.lower())\n",
    "\n",
    "        # 3. Numericalize Source (English)\n",
    "        # Use .get() to map unknown words to <unk> index\n",
    "        src_indices = [self.en_vocab.get(token, self.unk_idx_en) for token in src_tokens]\n",
    "        \n",
    "        # 4. Numericalize Target (French)\n",
    "        trg_indices = [self.fr_vocab.get(token, self.unk_idx_fr) for token in trg_tokens]\n",
    "\n",
    "        # 5. Add Special Tokens\n",
    "        # Source usually needs <eos> at the end so the LSTM knows the sentence stopped\n",
    "        src_indices.append(self.eos_idx_en)\n",
    "        \n",
    "        # Target needs <sos> to start generation and <eos> to end it\n",
    "        trg_indices = [self.sos_idx_fr] + trg_indices + [self.eos_idx_fr]\n",
    "\n",
    "        return torch.tensor(src_indices, dtype=torch.long), torch.tensor(trg_indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d80f4-c634-4be8-90ec-24c4e631caa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ea23429-fdac-48fe-829b-59ed9a153ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanewdataset=TranslationDataset(data,en_vocab,fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7bccd8c-4881-409a-8e1f-e4e50fff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # 'batch' is a list of tuples: [(input_tensor_1, target_tensor_1), (input_tensor_2, target_tensor_2), ...]\n",
    "\n",
    "    # 1. Separate inputs and targets\n",
    "    inputs = [torch.tensor(item[0]) for item in batch]\n",
    "    targets = [torch.tensor(item[1]) for item in batch]\n",
    "\n",
    "    # 2. Pad the inputs and targets to the length of the longest sequence in the batch\n",
    "    # batch_first=True makes the output shape (BatchSize, SequenceLength)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b51b6de-3ca3-481d-9119-6dc6772d3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "haha=DataLoader(datanewdataset,batch_size=32,shuffle=True,collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce07bd-19b3-43ad-a820-3e009ea3ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d26a01-a545-495f-b951-878ee45e667a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b364586-8172-4ecf-96db-b1e781b20ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62a31a-6579-4f09-a820-810e546e45ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3050c-9edc-4dd6-ba85-46e4abc9f95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaf9879c-de35-4cb7-b158-b51608fd6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa=torch.randn(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a435a35-e05b-4e98-8c7a-d28669943f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ha=nn.LSTM(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e076d8cb-7094-4dea-8a85-af2cf4064cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya=ha(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f497155-a726-4de9-a4f9-dc4b85034d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 200])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be3400ae-aaa7-4f69-965a-a7b0e64e4bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da92149f-7fcc-44a4-b1cb-ca91e63dee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01357329-82cc-4c9a-9a8b-b16da3c77f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=300\n",
    "#since using pre trained Fast TExt aligned vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cc29a79-b82a-461d-bd5a-56f3f0f5809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_ENC=len(en_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acde860c-f52a-4ac4-8001-d654390c5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_FR=len(fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "131b12a5-301d-49a1-ad20-39ce0d4ed017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(en_weights, freeze=True)\n",
    "        self.lstm=nn.LSTM(input_size=embed_dim,hidden_size=1024,num_layers=3,batch_first=True,bidirectional=False)\n",
    "        self.rel=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        embx=self.emb(x)\n",
    "        out,(hid,cell)=self.lstm(embx)\n",
    "        return hid,cell\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e0325b-9f5a-4cac-8c39-cc110150b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(fr_weights, freeze=True)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=1024, num_layers=3, batch_first=True, bidirectional=False)\n",
    "        self.fc_out = nn.Linear(1024, VOCAB_SIZE_FR) # Map hidden state to Vocab Size\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: [batch_size] -> unsqueeze to [batch_size, 1]\n",
    "        x = x.unsqueeze(1)\n",
    "        embx = self.emb(x)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embx, (hidden, cell))\n",
    "        \n",
    "        # prediction shape: [batch_size, VOCAB_SIZE]\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b18a04e6-e8e8-4ebd-a79d-ee5cb8215acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        # source: [batch, src_len]\n",
    "        # target: [batch, trg_len]\n",
    "        \n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        vocab_size = len(fr_vocab)\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
    "        \n",
    "        # 1. Encode\n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # 2. First input to decoder (Start Token)\n",
    "        # We use the SOS_TOKEN_ID defined at the top\n",
    "        input_token = torch.full((batch_size,), SOS_TOKEN_ID, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        # 3. Decode\n",
    "        for t in range(target_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            # Teacher forcing\n",
    "            top1 = output.argmax(1)\n",
    "            use_teacher = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # If using teacher forcing, next input is actual target token\n",
    "            # Else, next input is predicted token\n",
    "            if t < target_len - 1:\n",
    "                input_token = target[:, t] if use_teacher else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c98af8-de0c-4fdb-8d5f-96182a77a86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea5342fc-fa59-45f5-a51a-abe8bba6a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "encoder = enc()\n",
    "decoder = dec()\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Optimization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245a233c-efba-49bb-8bdd-38b6e95e0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, iterator, optimizer, criterion,epoch, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for kek in range(epoch):\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(src, trg)\n",
    "            \n",
    "            # Reshape for Loss\n",
    "            # output: [batch, len, vocab] -> [batch*len, vocab]\n",
    "            # trg: [batch, len] -> [batch*len]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.view(-1, output_dim)\n",
    "            trg = trg.view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients to prevent explosion\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if i % 500 == 0:\n",
    "                print(f\"Epoch number {kek} batch {i}, Loss: {loss.item()}\")\n",
    "                \n",
    "        print( epoch_loss / len(iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad57f94-632f-4743-ab24-c72969621b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_translation(model, sentence, max_len=20):\n",
    "    model.eval()\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # 1. Preprocess the Input (English)\n",
    "    # ---------------------------------------------\n",
    "    # Use the same tokenization function as training\n",
    "    tokens = tokenize_en(sentence.lower())\n",
    "    \n",
    "    # Manually convert tokens to IDs using en_vocab\n",
    "    # Handle unknown words with .get(token, unk_index)\n",
    "    unk_idx = en_vocab.get('<unk>', 3) \n",
    "    eos_idx = en_vocab.get('<eos>', 2)\n",
    "    \n",
    "    ids = [en_vocab.get(token, unk_idx) for token in tokens]\n",
    "    \n",
    "    # IMPORTANT: Add <eos> if your model was trained with it\n",
    "    ids.append(eos_idx)\n",
    "    \n",
    "    src_tensor = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device) # [1, seq_len]\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 2. Encode\n",
    "    # ---------------------------------------------\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 3. Decode Loop\n",
    "    # ---------------------------------------------\n",
    "    # Get special tokens for French\n",
    "    sos_idx = fr_vocab['<sos>']\n",
    "    eos_idx = fr_vocab['<eos>']\n",
    "    \n",
    "    inputs = [sos_idx]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        input_tensor = torch.tensor([inputs[-1]], dtype=torch.long).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(input_tensor, hidden, cell)\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        \n",
    "        # Stop if EOS is predicted\n",
    "        if pred_token == eos_idx:\n",
    "            break\n",
    "        \n",
    "        inputs.append(pred_token)\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 4. Convert IDs back to Words (French)\n",
    "    # ---------------------------------------------\n",
    "    # We need to invert the fr_vocab dictionary (ID -> Word)\n",
    "    # ideally, do this once globally, but here is fine for inference\n",
    "    idx_to_word = {v: k for k, v in fr_vocab.items()}\n",
    "    \n",
    "    # Skip the first token (which is SOS)\n",
    "    predicted_tokens = [idx_to_word.get(idx, '<unk>') for idx in inputs[1:]]\n",
    "    \n",
    "    return \" \".join(predicted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6f997ef-be5f-40db-bcf1-b6ab69807cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_17304\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_17304\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0 batch 0, Loss: 10.111145973205566\n",
      "Epoch number 0 batch 500, Loss: 4.8358283042907715\n",
      "Epoch number 0 batch 1000, Loss: 4.240336894989014\n",
      "Epoch number 0 batch 1500, Loss: 4.01328706741333\n",
      "Epoch number 0 batch 2000, Loss: 3.7634356021881104\n",
      "Epoch number 0 batch 2500, Loss: 4.302215576171875\n",
      "Epoch number 0 batch 3000, Loss: 3.6970086097717285\n",
      "Epoch number 0 batch 3500, Loss: 3.7250916957855225\n",
      "Epoch number 0 batch 4000, Loss: 3.2472798824310303\n",
      "Epoch number 0 batch 4500, Loss: 3.327038049697876\n",
      "Epoch number 0 batch 5000, Loss: 3.6872339248657227\n",
      "3.8949108085990236\n",
      "Epoch number 1 batch 0, Loss: 3.3789267539978027\n",
      "Epoch number 1 batch 500, Loss: 3.486088752746582\n",
      "Epoch number 1 batch 1000, Loss: 3.4611101150512695\n",
      "Epoch number 1 batch 1500, Loss: 3.2933602333068848\n",
      "Epoch number 1 batch 2000, Loss: 2.9352400302886963\n",
      "Epoch number 1 batch 2500, Loss: 3.0420103073120117\n",
      "Epoch number 1 batch 3000, Loss: 2.840574264526367\n",
      "Epoch number 1 batch 3500, Loss: 2.8554234504699707\n",
      "Epoch number 1 batch 4000, Loss: 3.1175193786621094\n",
      "Epoch number 1 batch 4500, Loss: 2.6934471130371094\n",
      "Epoch number 1 batch 5000, Loss: 2.60701322555542\n",
      "6.850612539110515\n",
      "Epoch number 2 batch 0, Loss: 2.5625431537628174\n",
      "Epoch number 2 batch 500, Loss: 2.295201301574707\n",
      "Epoch number 2 batch 1000, Loss: 2.4629945755004883\n",
      "Epoch number 2 batch 1500, Loss: 2.260200023651123\n",
      "Epoch number 2 batch 2000, Loss: 2.3843255043029785\n",
      "Epoch number 2 batch 2500, Loss: 3.0460853576660156\n",
      "Epoch number 2 batch 3000, Loss: 2.2267518043518066\n",
      "Epoch number 2 batch 3500, Loss: 2.1706316471099854\n",
      "Epoch number 2 batch 4000, Loss: 2.4388325214385986\n",
      "Epoch number 2 batch 4500, Loss: 2.491272449493408\n",
      "Epoch number 2 batch 5000, Loss: 2.313765048980713\n",
      "9.213146567388101\n",
      "Epoch number 3 batch 0, Loss: 2.174452304840088\n",
      "Epoch number 3 batch 500, Loss: 2.063936710357666\n",
      "Epoch number 3 batch 1000, Loss: 2.086667060852051\n",
      "Epoch number 3 batch 1500, Loss: 2.673644781112671\n",
      "Epoch number 3 batch 2000, Loss: 1.8327481746673584\n",
      "Epoch number 3 batch 2500, Loss: 1.7566626071929932\n",
      "Epoch number 3 batch 3000, Loss: 2.3493881225585938\n",
      "Epoch number 3 batch 3500, Loss: 2.0285606384277344\n",
      "Epoch number 3 batch 4000, Loss: 2.0281624794006348\n",
      "Epoch number 3 batch 4500, Loss: 2.0911364555358887\n",
      "Epoch number 3 batch 5000, Loss: 2.5149965286254883\n",
      "11.157111087964301\n",
      "Epoch number 4 batch 0, Loss: 1.6338547468185425\n",
      "Epoch number 4 batch 500, Loss: 1.3212239742279053\n",
      "Epoch number 4 batch 1000, Loss: 1.8996806144714355\n",
      "Epoch number 4 batch 1500, Loss: 1.4634946584701538\n",
      "Epoch number 4 batch 2000, Loss: 1.380453109741211\n",
      "Epoch number 4 batch 2500, Loss: 2.0132944583892822\n",
      "Epoch number 4 batch 3000, Loss: 1.222717523574829\n",
      "Epoch number 4 batch 3500, Loss: 1.6538530588150024\n",
      "Epoch number 4 batch 4000, Loss: 1.5468864440917969\n",
      "Epoch number 4 batch 4500, Loss: 1.803682804107666\n",
      "Epoch number 4 batch 5000, Loss: 1.5100889205932617\n",
      "12.813409012683126\n",
      "Epoch number 5 batch 0, Loss: 1.4335377216339111\n",
      "Epoch number 5 batch 500, Loss: 1.2123013734817505\n",
      "Epoch number 5 batch 1000, Loss: 1.666435956954956\n",
      "Epoch number 5 batch 1500, Loss: 1.3369436264038086\n",
      "Epoch number 5 batch 2000, Loss: 1.3756227493286133\n",
      "Epoch number 5 batch 2500, Loss: 1.6391023397445679\n",
      "Epoch number 5 batch 3000, Loss: 1.9930185079574585\n",
      "Epoch number 5 batch 3500, Loss: 1.8872976303100586\n",
      "Epoch number 5 batch 4000, Loss: 1.5279923677444458\n",
      "Epoch number 5 batch 4500, Loss: 1.7029545307159424\n",
      "Epoch number 5 batch 5000, Loss: 1.4644732475280762\n",
      "14.256988122405023\n",
      "Epoch number 6 batch 0, Loss: 1.06438148021698\n",
      "Epoch number 6 batch 500, Loss: 1.3910332918167114\n",
      "Epoch number 6 batch 1000, Loss: 1.3678219318389893\n",
      "Epoch number 6 batch 1500, Loss: 0.9905382990837097\n",
      "Epoch number 6 batch 2000, Loss: 1.2338238954544067\n",
      "Epoch number 6 batch 2500, Loss: 0.8562957048416138\n",
      "Epoch number 6 batch 3000, Loss: 1.5366765260696411\n",
      "Epoch number 6 batch 3500, Loss: 1.2427802085876465\n",
      "Epoch number 6 batch 4000, Loss: 1.4440146684646606\n",
      "Epoch number 6 batch 4500, Loss: 1.7907263040542603\n",
      "Epoch number 6 batch 5000, Loss: 0.964270293712616\n",
      "15.536183920958194\n",
      "Epoch number 7 batch 0, Loss: 1.5025131702423096\n",
      "Epoch number 7 batch 500, Loss: 0.8273203372955322\n",
      "Epoch number 7 batch 1000, Loss: 0.8593942523002625\n",
      "Epoch number 7 batch 1500, Loss: 1.6494114398956299\n",
      "Epoch number 7 batch 2000, Loss: 1.4905149936676025\n",
      "Epoch number 7 batch 2500, Loss: 1.0313128232955933\n",
      "Epoch number 7 batch 3000, Loss: 0.8830103874206543\n",
      "Epoch number 7 batch 3500, Loss: 1.3096837997436523\n",
      "Epoch number 7 batch 4000, Loss: 1.502060055732727\n",
      "Epoch number 7 batch 4500, Loss: 1.2885555028915405\n",
      "Epoch number 7 batch 5000, Loss: 1.1262798309326172\n",
      "16.683508343721787\n",
      "Epoch number 8 batch 0, Loss: 0.7645167112350464\n",
      "Epoch number 8 batch 500, Loss: 1.009543776512146\n",
      "Epoch number 8 batch 1000, Loss: 0.9299169182777405\n",
      "Epoch number 8 batch 1500, Loss: 0.8568198680877686\n",
      "Epoch number 8 batch 2000, Loss: 0.8135116100311279\n",
      "Epoch number 8 batch 2500, Loss: 0.8463302850723267\n",
      "Epoch number 8 batch 3000, Loss: 1.091947078704834\n",
      "Epoch number 8 batch 3500, Loss: 0.8482893705368042\n",
      "Epoch number 8 batch 4000, Loss: 0.6981505155563354\n",
      "Epoch number 8 batch 4500, Loss: 0.9018622040748596\n",
      "Epoch number 8 batch 5000, Loss: 0.8074502348899841\n",
      "17.71847592584421\n",
      "Epoch number 9 batch 0, Loss: 0.8562164306640625\n",
      "Epoch number 9 batch 500, Loss: 0.7841644287109375\n",
      "Epoch number 9 batch 1000, Loss: 0.7872653603553772\n",
      "Epoch number 9 batch 1500, Loss: 0.6707887649536133\n",
      "Epoch number 9 batch 2000, Loss: 1.0039039850234985\n",
      "Epoch number 9 batch 2500, Loss: 0.8801757097244263\n",
      "Epoch number 9 batch 3000, Loss: 0.8055916428565979\n",
      "Epoch number 9 batch 3500, Loss: 1.1740466356277466\n",
      "Epoch number 9 batch 4000, Loss: 0.8559284806251526\n",
      "Epoch number 9 batch 4500, Loss: 0.9122499227523804\n",
      "Epoch number 9 batch 5000, Loss: 0.9562775492668152\n",
      "18.663664151766973\n",
      "Epoch Loss: None\n"
     ]
    }
   ],
   "source": [
    "# Example run (Uncomment to train)\n",
    "print(\"Starting Training...\")\n",
    "loss = train_one_epoch(model, haha, optimizer, criterion,epoch=10)\n",
    "print(f\"Epoch Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b7e3f8f-d6da-4da4-af41-912f1af43436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> je suis parfaite . c' est tout toi   ?\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"I am doing great , WHat about you?\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fbb0ee85-442a-4a6c-b716-60b44e0942c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> c' est une bonne journée .\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"Today's a good day.\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9141b069-f181-4020-af2b-09da36289d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> comment s' est passé   ?\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"How was prison?\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55df86d9-181f-4520-b800-706bab33aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> coupe la dents .\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"Bite the bullet.\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47dd041d-22f5-4e66-a5fe-4cb4c34dff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> quelle est la heure ?\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"what's the time?\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb85ec46-0737-432c-b469-a84cd8cb2e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> quelle est le   ?\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"what's the time\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "298b7553-6b90-41b4-933f-4c9cb4316c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> quel musée est -t -elle   ?\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"whats the time?\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cb60e3f-c194-4343-ac3d-f177bd171cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> comporte - toi   !\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"behave yourself\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68f7583f-2c2b-4990-b4e3-b40b781745e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> s' il vous plaît , arrêtez .\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"please stop!\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e88ecf3-e377-46b2-abd9-7d7006547e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: <sos> je vous prie !\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"please stop\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11dc32-99d7-43f7-a610-052579da6977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
