{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "03fd3d8b-bef9-4182-9c47-04ed5b94f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "#from torchvision import Datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e5bfb-6be0-4cf7-bd9a-838083f45a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('engfrench.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9de6cd-6070-4bb0-8a97-c5cfb6d3cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175621\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16df2aed-79f6-4a10-af85-e10d4a10a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    The guards found a hacksaw blade in the prison...\n",
       "French words/sentences     Les gardiens trouvèrent une lame de scie à mét...\n",
       "Name: 170000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[170000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb501df-06b8-4e87-9368-7f092b965c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf3bbe2-1054-4b10-a572-942a56398c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115e8e84096b4993892fdfcf90fd8674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/428 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maddo\\.cache\\huggingface\\hub\\models--Cohere--multilingual-22-12. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5100184f264649d4bdbf03da5b1c3661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f37e088bba3454592b0d4390658a6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/10.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb9c30ddba54add894966460097ef52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Cohere/multilingual-22-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d31611e-192e-4b2a-bafb-06ca5a82ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN_ID=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82ed24b-8349-4eb7-b1d3-bbc3e5a9aa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'additional_special_tokens': [' _ENFR_ ']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73cf3179-1b66-40fb-adac-a22ca0fc5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN_ID = tokenizer.cls_token_id if tokenizer.cls_token_id is not None else 0\n",
    "EOS_TOKEN_ID = tokenizer.sep_token_id if tokenizer.sep_token_id is not None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "94f06527-e676-4c98-962a-2c4f64ec51b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 501160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8165ff4-0c6a-443e-b3bc-7b9defd201fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txten=data.iloc[0,0]\n",
    "txtfr=data.iloc[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841c7d65-e445-45da-9b8c-605193c87e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b3ef1e-ee68-42a6-add8-02108412f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salut!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b442642-9864-4abe-964a-0962c019ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=tokenizer.tokenize(txten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9807bd50-6f79-4cfe-8ab4-70c8452ab35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00150b0b-562c-4841-9f3d-b2a91a887333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenfr=tokenizer.tokenize(txtfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e10fdb-af49-480b-b328-463d6a9d0966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salut', '!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e05a206-9c64-486d-a8dc-af8ff0d6c01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c5e98b-dc48-4e83-a5a0-db5f3c63f674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e467a03-80e6-4410-a4c9-524ee18b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dat=txten+' _ENFR_ '+txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d322c4-82e8-4f77-b383-952d0adcf115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi. _ENFR_ Salut!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "343d84ce-55d7-40b4-b8bf-d6eccf55dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokdat=(tokenizer.tokenize(dat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76738948-f959-48e6-ae72-0377e830a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', '.', ' _ENFR_ ', 'Salut', '!']\n"
     ]
    }
   ],
   "source": [
    "print(tokdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3515c824-8ee0-4d00-87e6-611644278735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokdat=tokenizer.convert_tokens_to_ids(tokdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96762560-c0a4-45ba-92e7-6e37f8460323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4780c5e0-09f2-4fdd-b77a-ccaf6f336772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 22293\n",
      "[22293] 119\n",
      "[22293, 119] 501153\n",
      "[22293, 119, 501153] 83440\n",
      "[22293, 119, 501153, 83440] 106\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokdat)):\n",
    "    print(tokdat[:i],tokdat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dfb4c38-f5c7-4858-8734-f1ee732f9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,x):\n",
    "        self.x=x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,i):\n",
    "        inp=self.x\n",
    "        return torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inp.iloc[i,0]))),torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inp.iloc[i,1])))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d80f4-c634-4be8-90ec-24c4e631caa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ea23429-fdac-48fe-829b-59ed9a153ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanewdataset=dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45d2fdc9-807a-427f-ad75-24e70c1b8424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ne t ' en va pas!\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(datanewdataset[2000][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0b1de5d-ae48-49ff-8209-d8ee1bebb7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don ' t leave!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(datanewdataset[2000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7bccd8c-4881-409a-8e1f-e4e50fff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # 'batch' is a list of tuples: [(input_tensor_1, target_tensor_1), (input_tensor_2, target_tensor_2), ...]\n",
    "\n",
    "    # 1. Separate inputs and targets\n",
    "    inputs = [torch.tensor(item[0]) for item in batch]\n",
    "    targets = [torch.tensor(item[1]) for item in batch]\n",
    "\n",
    "    # 2. Pad the inputs and targets to the length of the longest sequence in the batch\n",
    "    # batch_first=True makes the output shape (BatchSize, SequenceLength)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b51b6de-3ca3-481d-9119-6dc6772d3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "haha=DataLoader(datanewdataset,batch_size=32,shuffle=True,collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce07bd-19b3-43ad-a820-3e009ea3ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09d26a01-a545-495f-b951-878ee45e667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedsize=len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b364586-8172-4ecf-96db-b1e781b20ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501154\n"
     ]
    }
   ],
   "source": [
    "print(embedsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86a3050c-9edc-4dd6-ba85-46e4abc9f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y a - t - il un endroit en Europe que tu veuilles visiter? [PAD]\n",
      "Is there somewhere in Europe you ' d like to visit?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(haha):\n",
    "    print(tokenizer.decode(x[1][0]))\n",
    "    print(tokenizer.decode(x[0][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaf9879c-de35-4cb7-b158-b51608fd6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa=torch.randn(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a435a35-e05b-4e98-8c7a-d28669943f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ha=nn.LSTM(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e076d8cb-7094-4dea-8a85-af2cf4064cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya=ha(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f497155-a726-4de9-a4f9-dc4b85034d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 200])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be3400ae-aaa7-4f69-965a-a7b0e64e4bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da92149f-7fcc-44a4-b1cb-ca91e63dee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01357329-82cc-4c9a-9a8b-b16da3c77f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "131b12a5-301d-49a1-ad20-39ce0d4ed017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb=nn.Embedding(501160,10)\n",
    "        self.lstm=nn.LSTM(input_size=10,hidden_size=100,num_layers=3,batch_first=True,bidirectional=False)\n",
    "        self.rel=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        embx=self.emb(x)\n",
    "        out,(hid,cell)=self.lstm(embx)\n",
    "        return hid,cell\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09e0325b-9f5a-4cac-8c39-cc110150b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, 10)\n",
    "        self.lstm = nn.LSTM(input_size=10, hidden_size=100, num_layers=3, batch_first=True, bidirectional=False)\n",
    "        self.fc_out = nn.Linear(100, VOCAB_SIZE) # Map hidden state to Vocab Size\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: [batch_size] -> unsqueeze to [batch_size, 1]\n",
    "        x = x.unsqueeze(1)\n",
    "        embx = self.emb(x)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embx, (hidden, cell))\n",
    "        \n",
    "        # prediction shape: [batch_size, VOCAB_SIZE]\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b18a04e6-e8e8-4ebd-a79d-ee5cb8215acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        # source: [batch, src_len]\n",
    "        # target: [batch, trg_len]\n",
    "        \n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        vocab_size = VOCAB_SIZE\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
    "        \n",
    "        # 1. Encode\n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # 2. First input to decoder (Start Token)\n",
    "        # We use the SOS_TOKEN_ID defined at the top\n",
    "        input_token = torch.full((batch_size,), SOS_TOKEN_ID, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        # 3. Decode\n",
    "        for t in range(target_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            # Teacher forcing\n",
    "            top1 = output.argmax(1)\n",
    "            use_teacher = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # If using teacher forcing, next input is actual target token\n",
    "            # Else, next input is predicted token\n",
    "            if t < target_len - 1:\n",
    "                input_token = target[:, t] if use_teacher else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c98af8-de0c-4fdb-8d5f-96182a77a86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea5342fc-fa59-45f5-a51a-abe8bba6a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "encoder = enc()\n",
    "decoder = dec()\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Optimization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "245a233c-efba-49bb-8bdd-38b6e95e0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, iterator, optimizer, criterion, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # Reshape for Loss\n",
    "        # output: [batch, len, vocab] -> [batch*len, vocab]\n",
    "        # trg: [batch, len] -> [batch*len]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.view(-1, output_dim)\n",
    "        trg = trg.view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients to prevent explosion\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss.item()}\")\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6ad57f94-632f-4743-ab24-c72969621b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_translation(model, sentence, max_len=20):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize input\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    src_tensor = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device) # [1, seq_len]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "    \n",
    "    # Start with SOS token\n",
    "    inputs = [SOS_TOKEN_ID]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        input_tensor = torch.tensor([inputs[-1]], dtype=torch.long).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(input_tensor, hidden, cell)\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        inputs.append(pred_token)\n",
    "        \n",
    "        # Stop if EOS or padding is predicted\n",
    "        if pred_token == EOS_TOKEN_ID or pred_token == PAD_TOKEN_ID:\n",
    "            break\n",
    "            \n",
    "    # Convert IDs back to tokens\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(inputs[1:]) # Skip SOS\n",
    "    return tokenizer.convert_tokens_to_string(predicted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6f997ef-be5f-40db-bcf1-b6ab69807cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 13.119987487792969\n",
      "Batch 10, Loss: 12.9395751953125\n",
      "Batch 20, Loss: 11.217743873596191\n",
      "Batch 30, Loss: 9.204442024230957\n",
      "Batch 40, Loss: 7.543518543243408\n",
      "Batch 50, Loss: 6.7631988525390625\n",
      "Batch 60, Loss: 6.942978858947754\n",
      "Batch 70, Loss: 6.657811641693115\n",
      "Batch 80, Loss: 6.904018878936768\n",
      "Batch 90, Loss: 6.449203014373779\n",
      "Batch 100, Loss: 6.499974250793457\n",
      "Batch 110, Loss: 6.70802116394043\n",
      "Batch 120, Loss: 6.178584575653076\n",
      "Batch 130, Loss: 6.21954870223999\n",
      "Batch 140, Loss: 6.309323310852051\n",
      "Batch 150, Loss: 6.672277450561523\n",
      "Batch 160, Loss: 6.6075568199157715\n",
      "Batch 170, Loss: 6.3702521324157715\n",
      "Batch 180, Loss: 6.683192729949951\n",
      "Batch 190, Loss: 6.3405327796936035\n",
      "Batch 200, Loss: 6.370121955871582\n",
      "Batch 210, Loss: 6.286919116973877\n",
      "Batch 220, Loss: 6.384129524230957\n",
      "Batch 230, Loss: 6.0717997550964355\n",
      "Batch 240, Loss: 6.195898532867432\n",
      "Batch 250, Loss: 6.632014274597168\n",
      "Batch 260, Loss: 6.346672058105469\n",
      "Batch 270, Loss: 6.0875935554504395\n",
      "Batch 280, Loss: 6.171433925628662\n",
      "Batch 290, Loss: 6.151162147521973\n",
      "Batch 300, Loss: 6.123415946960449\n",
      "Batch 310, Loss: 6.291849613189697\n",
      "Batch 320, Loss: 6.342331886291504\n",
      "Batch 330, Loss: 5.921150207519531\n",
      "Batch 340, Loss: 6.3412885665893555\n",
      "Batch 350, Loss: 5.886892318725586\n",
      "Batch 360, Loss: 6.1087751388549805\n",
      "Batch 370, Loss: 6.259194374084473\n",
      "Batch 380, Loss: 6.289307117462158\n",
      "Batch 390, Loss: 6.247529983520508\n",
      "Batch 400, Loss: 6.329200744628906\n",
      "Batch 410, Loss: 6.113307476043701\n",
      "Batch 420, Loss: 6.262373924255371\n",
      "Batch 430, Loss: 6.591145992279053\n",
      "Batch 440, Loss: 5.865027904510498\n",
      "Batch 450, Loss: 6.041641712188721\n",
      "Batch 460, Loss: 6.123394012451172\n",
      "Batch 470, Loss: 5.93494987487793\n",
      "Batch 480, Loss: 6.198794364929199\n",
      "Batch 490, Loss: 5.986588001251221\n",
      "Batch 500, Loss: 6.130199909210205\n",
      "Batch 510, Loss: 6.1672139167785645\n",
      "Batch 520, Loss: 5.680454254150391\n",
      "Batch 530, Loss: 6.198365211486816\n",
      "Batch 540, Loss: 6.180706024169922\n",
      "Batch 550, Loss: 6.2338643074035645\n",
      "Batch 560, Loss: 5.812206268310547\n",
      "Batch 570, Loss: 6.02392578125\n",
      "Batch 580, Loss: 5.922222137451172\n",
      "Batch 590, Loss: 6.0170207023620605\n",
      "Batch 600, Loss: 6.009185314178467\n",
      "Batch 610, Loss: 5.86417293548584\n",
      "Batch 620, Loss: 5.791871070861816\n",
      "Batch 630, Loss: 5.763556480407715\n",
      "Batch 640, Loss: 5.848509788513184\n",
      "Batch 650, Loss: 5.879818916320801\n",
      "Batch 660, Loss: 5.921888828277588\n",
      "Batch 670, Loss: 5.637620449066162\n",
      "Batch 680, Loss: 6.396088123321533\n",
      "Batch 690, Loss: 5.919345855712891\n",
      "Batch 700, Loss: 5.838284015655518\n",
      "Batch 710, Loss: 6.2537922859191895\n",
      "Batch 720, Loss: 5.652281284332275\n",
      "Batch 730, Loss: 5.791502475738525\n",
      "Batch 740, Loss: 5.918656349182129\n",
      "Batch 750, Loss: 6.1551408767700195\n",
      "Batch 760, Loss: 5.855892181396484\n",
      "Batch 770, Loss: 6.07835578918457\n",
      "Batch 780, Loss: 5.8103790283203125\n",
      "Batch 790, Loss: 5.835480690002441\n",
      "Batch 800, Loss: 5.630182266235352\n",
      "Batch 810, Loss: 5.82182502746582\n",
      "Batch 820, Loss: 6.004638671875\n",
      "Batch 830, Loss: 5.759853363037109\n",
      "Batch 840, Loss: 5.769789695739746\n",
      "Batch 850, Loss: 5.878990173339844\n",
      "Batch 860, Loss: 5.685624599456787\n",
      "Batch 870, Loss: 5.868052005767822\n",
      "Batch 880, Loss: 5.748103618621826\n",
      "Batch 890, Loss: 5.584605693817139\n",
      "Batch 900, Loss: 5.817070007324219\n",
      "Batch 910, Loss: 5.690030097961426\n",
      "Batch 920, Loss: 5.714669227600098\n",
      "Batch 930, Loss: 5.584435939788818\n",
      "Batch 940, Loss: 5.877023696899414\n",
      "Batch 950, Loss: 6.1354780197143555\n",
      "Batch 960, Loss: 5.912057399749756\n",
      "Batch 970, Loss: 5.891777992248535\n",
      "Batch 980, Loss: 5.7692060470581055\n",
      "Batch 990, Loss: 5.518019676208496\n",
      "Batch 1000, Loss: 5.614665508270264\n",
      "Batch 1010, Loss: 5.823789596557617\n",
      "Batch 1020, Loss: 5.531035900115967\n",
      "Batch 1030, Loss: 5.777592182159424\n",
      "Batch 1040, Loss: 5.470583915710449\n",
      "Batch 1050, Loss: 5.952691078186035\n",
      "Batch 1060, Loss: 5.89431095123291\n",
      "Batch 1070, Loss: 5.910107612609863\n",
      "Batch 1080, Loss: 5.725779056549072\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example run (Uncomment to train)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m loss \u001b[38;5;241m=\u001b[39m train_one_epoch(model, haha, optimizer, criterion)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[125], line 28\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     25\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 28\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example run (Uncomment to train)\n",
    "print(\"Starting Training...\")\n",
    "loss = train_one_epoch(model, haha, optimizer, criterion)\n",
    "print(f\"Epoch Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1b7e3f8f-d6da-4da4-af41-912f1af43436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: '...................\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"Hello HI\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0ee85-442a-4a6c-b716-60b44e0942c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141b069-f181-4020-af2b-09da36289d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df86d9-181f-4520-b800-706bab33aae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd041d-22f5-4e66-a5fe-4cb4c34dff46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
