{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fd3d8b-bef9-4182-9c47-04ed5b94f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "#from torchvision import Datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812e5bfb-6be0-4cf7-bd9a-838083f45a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('engfrench.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c9de6cd-6070-4bb0-8a97-c5cfb6d3cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175621\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16df2aed-79f6-4a10-af85-e10d4a10a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    The guards found a hacksaw blade in the prison...\n",
       "French words/sentences     Les gardiens trouvèrent une lame de scie à mét...\n",
       "Name: 170000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[170000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb501df-06b8-4e87-9368-7f092b965c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf3bbe2-1054-4b10-a572-942a56398c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115e8e84096b4993892fdfcf90fd8674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/428 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maddo\\.cache\\huggingface\\hub\\models--Cohere--multilingual-22-12. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5100184f264649d4bdbf03da5b1c3661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f37e088bba3454592b0d4390658a6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/10.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb9c30ddba54add894966460097ef52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Cohere/multilingual-22-12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d31611e-192e-4b2a-bafb-06ca5a82ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN_ID=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82ed24b-8349-4eb7-b1d3-bbc3e5a9aa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'additional_special_tokens': [' _ENFR_ ']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8165ff4-0c6a-443e-b3bc-7b9defd201fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txten=data.iloc[0,0]\n",
    "txtfr=data.iloc[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841c7d65-e445-45da-9b8c-605193c87e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b3ef1e-ee68-42a6-add8-02108412f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salut!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b442642-9864-4abe-964a-0962c019ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=tokenizer.tokenize(txten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9807bd50-6f79-4cfe-8ab4-70c8452ab35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00150b0b-562c-4841-9f3d-b2a91a887333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenfr=tokenizer.tokenize(txtfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91e10fdb-af49-480b-b328-463d6a9d0966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salut', '!']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e05a206-9c64-486d-a8dc-af8ff0d6c01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c5e98b-dc48-4e83-a5a0-db5f3c63f674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e467a03-80e6-4410-a4c9-524ee18b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dat=txten+' _ENFR_ '+txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2d322c4-82e8-4f77-b383-952d0adcf115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi. _ENFR_ Salut!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "343d84ce-55d7-40b4-b8bf-d6eccf55dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokdat=(tokenizer.tokenize(dat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76738948-f959-48e6-ae72-0377e830a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', '.', ' _ENFR_ ', 'Salut', '!']\n"
     ]
    }
   ],
   "source": [
    "print(tokdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3515c824-8ee0-4d00-87e6-611644278735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokdat=tokenizer.convert_tokens_to_ids(tokdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96762560-c0a4-45ba-92e7-6e37f8460323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4780c5e0-09f2-4fdd-b77a-ccaf6f336772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 22293\n",
      "[22293] 119\n",
      "[22293, 119] 501153\n",
      "[22293, 119, 501153] 83440\n",
      "[22293, 119, 501153, 83440] 106\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokdat)):\n",
    "    print(tokdat[:i],tokdat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dfb4c38-f5c7-4858-8734-f1ee732f9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,x):\n",
    "        self.x=x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,i):\n",
    "        inp=self.x\n",
    "        return torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inp.iloc[i,0]))),torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inp.iloc[i,1])))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d80f4-c634-4be8-90ec-24c4e631caa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ea23429-fdac-48fe-829b-59ed9a153ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanewdataset=dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45d2fdc9-807a-427f-ad75-24e70c1b8424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ne t ' en va pas!\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(datanewdataset[2000][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0b1de5d-ae48-49ff-8209-d8ee1bebb7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don ' t leave!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(datanewdataset[2000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7bccd8c-4881-409a-8e1f-e4e50fff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # 'batch' is a list of tuples: [(input_tensor_1, target_tensor_1), (input_tensor_2, target_tensor_2), ...]\n",
    "\n",
    "    # 1. Separate inputs and targets\n",
    "    inputs = [torch.tensor(item[0]) for item in batch]\n",
    "    targets = [torch.tensor(item[1]) for item in batch]\n",
    "\n",
    "    # 2. Pad the inputs and targets to the length of the longest sequence in the batch\n",
    "    # batch_first=True makes the output shape (BatchSize, SequenceLength)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b51b6de-3ca3-481d-9119-6dc6772d3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "haha=DataLoader(datanewdataset,batch_size=32,shuffle=True,collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce07bd-19b3-43ad-a820-3e009ea3ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09d26a01-a545-495f-b951-878ee45e667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedsize=len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b364586-8172-4ecf-96db-b1e781b20ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501154\n"
     ]
    }
   ],
   "source": [
    "print(embedsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86a3050c-9edc-4dd6-ba85-46e4abc9f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y a - t - il un endroit en Europe que tu veuilles visiter? [PAD]\n",
      "Is there somewhere in Europe you ' d like to visit?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(haha):\n",
    "    print(tokenizer.decode(x[1][0]))\n",
    "    print(tokenizer.decode(x[0][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eaf9879c-de35-4cb7-b158-b51608fd6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa=torch.randn(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7a435a35-e05b-4e98-8c7a-d28669943f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ha=nn.LSTM(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e076d8cb-7094-4dea-8a85-af2cf4064cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya=ha(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f497155-a726-4de9-a4f9-dc4b85034d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 200])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be3400ae-aaa7-4f69-965a-a7b0e64e4bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da92149f-7fcc-44a4-b1cb-ca91e63dee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01357329-82cc-4c9a-9a8b-b16da3c77f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "131b12a5-301d-49a1-ad20-39ce0d4ed017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb=nn.Embedding(501160,10)\n",
    "        self.fc1=nn.Linear(10,100)\n",
    "        self.fc2=nn.Linear(100,200)\n",
    "        self.fc3=nn.Linear(200,1000)\n",
    "        self.fc4=nn.Linear(1000,5)\n",
    "        self.rel=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        embx=self.emb(x)\n",
    "        embx=self.rel(self.fc1(embx))\n",
    "        out=self.rel(self.fc2(embx))\n",
    "        out=self.rel(self.fc3(out))\n",
    "        out=self.fc4(out)\n",
    "        return out\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea5342fc-fa59-45f5-a51a-abe8bba6a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=enc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a233c-efba-49bb-8bdd-38b6e95e0e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad57f94-632f-4743-ab24-c72969621b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6f997ef-be5f-40db-bcf1-b6ab69807cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_24132\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(haha):\n",
    "    print(type(x[0]))\n",
    "    ha=encoder(x[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e3f8f-d6da-4da4-af41-912f1af43436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb0ee85-442a-4a6c-b716-60b44e0942c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141b069-f181-4020-af2b-09da36289d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df86d9-181f-4520-b800-706bab33aae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd041d-22f5-4e66-a5fe-4cb4c34dff46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
