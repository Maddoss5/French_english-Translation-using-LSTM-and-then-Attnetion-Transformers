{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03fd3d8b-bef9-4182-9c47-04ed5b94f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "#from torchvision import Datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "812e5bfb-6be0-4cf7-bd9a-838083f45a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('engfrench.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9de6cd-6070-4bb0-8a97-c5cfb6d3cad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175621\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16df2aed-79f6-4a10-af85-e10d4a10a9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English words/sentences    The guards found a hacksaw blade in the prison...\n",
       "French words/sentences     Les gardiens trouvèrent une lame de scie à mét...\n",
       "Name: 170000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[170000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "025efad2-8e80-47f1-a486-64a94073dc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English words/sentences</th>\n",
       "      <th>French words/sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>Be very careful.</td>\n",
       "      <td>Sois très prudente !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>Bees make honey.</td>\n",
       "      <td>Les abeilles font du miel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>Behave yourself.</td>\n",
       "      <td>Comporte-toi bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>Bite the bullet.</td>\n",
       "      <td>Serre les dents.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>Bite the bullet.</td>\n",
       "      <td>Serrez les dents.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      English words/sentences      French words/sentences\n",
       "10000        Be very careful.        Sois très prudente !\n",
       "10001        Bees make honey.  Les abeilles font du miel.\n",
       "10002        Behave yourself.          Comporte-toi bien.\n",
       "10003        Bite the bullet.            Serre les dents.\n",
       "10004        Bite the bullet.           Serrez les dents."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10000:10005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb501df-06b8-4e87-9368-7f092b965c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cf3bbe2-1054-4b10-a572-942a56398c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31910b03505b454e81b9322cb78037f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maddo\\.cache\\huggingface\\hub\\models--google-bert--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8940c365df114f47914463a7e180fd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4283747254b342ebb354cceea69b47b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36de91ee54bd44b98be183ad03cbd628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d31611e-192e-4b2a-bafb-06ca5a82ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN_ID=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d82ed24b-8349-4eb7-b1d3-bbc3e5a9aa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'additional_special_tokens': [' _ENFR_ ']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73cf3179-1b66-40fb-adac-a22ca0fc5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN_ID = tokenizer.cls_token_id if tokenizer.cls_token_id is not None else 0\n",
    "EOS_TOKEN_ID = tokenizer.sep_token_id if tokenizer.sep_token_id is not None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f06527-e676-4c98-962a-2c4f64ec51b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8165ff4-0c6a-443e-b3bc-7b9defd201fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "txten=data.iloc[0,0]\n",
    "txtfr=data.iloc[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841c7d65-e445-45da-9b8c-605193c87e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36b3ef1e-ee68-42a6-add8-02108412f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Salut!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b442642-9864-4abe-964a-0962c019ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=tokenizer.tokenize(txten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9807bd50-6f79-4cfe-8ab4-70c8452ab35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', '.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00150b0b-562c-4841-9f3d-b2a91a887333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenfr=tokenizer.tokenize(txtfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e10fdb-af49-480b-b328-463d6a9d0966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sal', '##ut', '!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e05a206-9c64-486d-a8dc-af8ff0d6c01c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58c5e98b-dc48-4e83-a5a0-db5f3c63f674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e467a03-80e6-4410-a4c9-524ee18b2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dat=txten+' _ENFR_ '+txtfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d322c4-82e8-4f77-b383-952d0adcf115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi. _ENFR_ Salut!'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "343d84ce-55d7-40b4-b8bf-d6eccf55dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokdat=(tokenizer.tokenize(dat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76738948-f959-48e6-ae72-0377e830a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', '.', ' _ENFR_ ', 'sal', '##ut', '!']\n"
     ]
    }
   ],
   "source": [
    "print(tokdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3515c824-8ee0-4d00-87e6-611644278735",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokdat=tokenizer.convert_tokens_to_ids(tokdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96762560-c0a4-45ba-92e7-6e37f8460323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4780c5e0-09f2-4fdd-b77a-ccaf6f336772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 7632\n",
      "[7632] 1012\n",
      "[7632, 1012] 30522\n",
      "[7632, 1012, 30522] 16183\n",
      "[7632, 1012, 30522, 16183] 4904\n",
      "[7632, 1012, 30522, 16183, 4904] 999\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokdat)):\n",
    "    print(tokdat[:i],tokdat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dfb4c38-f5c7-4858-8734-f1ee732f9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,x):\n",
    "        self.x=x\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,i):\n",
    "        inp=self.x\n",
    "        return torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inp.iloc[i,0]))),torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(inp.iloc[i,1])))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d80f4-c634-4be8-90ec-24c4e631caa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ea23429-fdac-48fe-829b-59ed9a153ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datanewdataset=dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45d2fdc9-807a-427f-ad75-24e70c1b8424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ne t'en va pas!\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(datanewdataset[2000][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0b1de5d-ae48-49ff-8209-d8ee1bebb7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"don't leave!\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(datanewdataset[2000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7bccd8c-4881-409a-8e1f-e4e50fff387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # 'batch' is a list of tuples: [(input_tensor_1, target_tensor_1), (input_tensor_2, target_tensor_2), ...]\n",
    "\n",
    "    # 1. Separate inputs and targets\n",
    "    inputs = [torch.tensor(item[0]) for item in batch]\n",
    "    targets = [torch.tensor(item[1]) for item in batch]\n",
    "\n",
    "    # 2. Pad the inputs and targets to the length of the longest sequence in the batch\n",
    "    # batch_first=True makes the output shape (BatchSize, SequenceLength)\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=PAD_TOKEN_ID)\n",
    "    \n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b51b6de-3ca3-481d-9119-6dc6772d3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "haha=DataLoader(datanewdataset,batch_size=32,shuffle=True,collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce07bd-19b3-43ad-a820-3e009ea3ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09d26a01-a545-495f-b951-878ee45e667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedsize=len(tokenizer.get_vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b364586-8172-4ecf-96db-b1e781b20ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30523\n"
     ]
    }
   ],
   "source": [
    "print(embedsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba62a31a-6579-4f09-a820-810e546e45ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=embedsize+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a3050c-9edc-4dd6-ba85-46e4abc9f95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vous m'avez prevenu, mais je n'ai pas ecoute. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "you warned me, but i didn't listen. [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_1896\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_1896\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(haha):\n",
    "    print(tokenizer.decode(x[1][0]))\n",
    "    print(tokenizer.decode(x[0][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaf9879c-de35-4cb7-b158-b51608fd6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa=torch.randn(10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a435a35-e05b-4e98-8c7a-d28669943f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ha=nn.LSTM(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e076d8cb-7094-4dea-8a85-af2cf4064cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya=ha(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f497155-a726-4de9-a4f9-dc4b85034d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 200])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be3400ae-aaa7-4f69-965a-a7b0e64e4bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da92149f-7fcc-44a4-b1cb-ca91e63dee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "01357329-82cc-4c9a-9a8b-b16da3c77f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "131b12a5-301d-49a1-ad20-39ce0d4ed017",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb=nn.Embedding(VOCAB_SIZE,embed_dim)\n",
    "        self.lstm=nn.LSTM(input_size=embed_dim,hidden_size=1024,num_layers=3,batch_first=True,bidirectional=False)\n",
    "        self.rel=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        embx=self.emb(x)\n",
    "        out,(hid,cell)=self.lstm(embx)\n",
    "        return hid,cell\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09e0325b-9f5a-4cac-8c39-cc110150b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dec(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE, embed_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=1024, num_layers=3, batch_first=True, bidirectional=False)\n",
    "        self.fc_out = nn.Linear(1024, VOCAB_SIZE) # Map hidden state to Vocab Size\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape: [batch_size] -> unsqueeze to [batch_size, 1]\n",
    "        x = x.unsqueeze(1)\n",
    "        embx = self.emb(x)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(embx, (hidden, cell))\n",
    "        \n",
    "        # prediction shape: [batch_size, VOCAB_SIZE]\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b18a04e6-e8e8-4ebd-a79d-ee5cb8215acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        # source: [batch, src_len]\n",
    "        # target: [batch, trg_len]\n",
    "        \n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[1]\n",
    "        vocab_size = VOCAB_SIZE\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
    "        \n",
    "        # 1. Encode\n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # 2. First input to decoder (Start Token)\n",
    "        # We use the SOS_TOKEN_ID defined at the top\n",
    "        input_token = torch.full((batch_size,), SOS_TOKEN_ID, dtype=torch.long).to(self.device)\n",
    "        \n",
    "        # 3. Decode\n",
    "        for t in range(target_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            # Teacher forcing\n",
    "            top1 = output.argmax(1)\n",
    "            use_teacher = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # If using teacher forcing, next input is actual target token\n",
    "            # Else, next input is predicted token\n",
    "            if t < target_len - 1:\n",
    "                input_token = target[:, t] if use_teacher else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c98af8-de0c-4fdb-8d5f-96182a77a86c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea5342fc-fa59-45f5-a51a-abe8bba6a991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "encoder = enc()\n",
    "decoder = dec()\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Optimization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "245a233c-efba-49bb-8bdd-38b6e95e0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, iterator, optimizer, criterion,epoch, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for kek in range(epoch):\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(src, trg)\n",
    "            \n",
    "            # Reshape for Loss\n",
    "            # output: [batch, len, vocab] -> [batch*len, vocab]\n",
    "            # trg: [batch, len] -> [batch*len]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.view(-1, output_dim)\n",
    "            trg = trg.view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients to prevent explosion\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if i % 200 == 0:\n",
    "                print(f\"Batch {i}, Loss: {loss.item()}\")\n",
    "                \n",
    "        return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ad57f94-632f-4743-ab24-c72969621b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_translation(model, sentence, max_len=20):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize input\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    src_tensor = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device) # [1, seq_len]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "    \n",
    "    # Start with SOS token\n",
    "    inputs = [SOS_TOKEN_ID]\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        input_tensor = torch.tensor([inputs[-1]], dtype=torch.long).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(input_tensor, hidden, cell)\n",
    "            \n",
    "        pred_token = output.argmax(1).item()\n",
    "        inputs.append(pred_token)\n",
    "        \n",
    "        # Stop if EOS or padding is predicted\n",
    "        if pred_token == EOS_TOKEN_ID or pred_token == PAD_TOKEN_ID:\n",
    "            break\n",
    "            \n",
    "    # Convert IDs back to tokens\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(inputs[1:]) # Skip SOS\n",
    "    return tokenizer.convert_tokens_to_string(predicted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6f997ef-be5f-40db-bcf1-b6ab69807cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Batch 0, Loss: 4.165121555328369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_1896\\1408414250.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = [torch.tensor(item[0]) for item in batch]\n",
      "C:\\Users\\maddo\\AppData\\Local\\Temp\\ipykernel_1896\\1408414250.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = [torch.tensor(item[1]) for item in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200, Loss: 4.199960708618164\n",
      "Batch 400, Loss: 3.232105255126953\n",
      "Batch 600, Loss: 3.4725232124328613\n",
      "Batch 800, Loss: 3.3705008029937744\n",
      "Batch 1000, Loss: 3.242098093032837\n",
      "Batch 1200, Loss: 3.515153169631958\n",
      "Batch 1400, Loss: 3.595393180847168\n",
      "Batch 1600, Loss: 4.001532077789307\n",
      "Batch 1800, Loss: 2.679044008255005\n",
      "Batch 2000, Loss: 2.5007336139678955\n",
      "Batch 2200, Loss: 3.3220736980438232\n",
      "Batch 2400, Loss: 2.552337884902954\n",
      "Batch 2600, Loss: 2.869300603866577\n",
      "Batch 2800, Loss: 2.706411361694336\n",
      "Batch 3000, Loss: 2.758835554122925\n",
      "Batch 3200, Loss: 2.8631083965301514\n",
      "Batch 3400, Loss: 2.3348615169525146\n",
      "Batch 3600, Loss: 2.8709332942962646\n",
      "Batch 3800, Loss: 2.9423513412475586\n",
      "Batch 4000, Loss: 2.77290678024292\n",
      "Batch 4200, Loss: 2.5807883739471436\n",
      "Batch 4400, Loss: 2.520583152770996\n",
      "Batch 4600, Loss: 2.343597888946533\n",
      "Batch 4800, Loss: 2.544912099838257\n",
      "Batch 5000, Loss: 2.928825855255127\n",
      "Batch 5200, Loss: 2.6749987602233887\n",
      "Batch 5400, Loss: 2.659404754638672\n",
      "Epoch Loss: 2.980877454477617\n"
     ]
    }
   ],
   "source": [
    "# Example run (Uncomment to train)\n",
    "print(\"Starting Training...\")\n",
    "loss = train_one_epoch(model, haha, optimizer, criterion,5)\n",
    "print(f\"Epoch Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b7e3f8f-d6da-4da4-af41-912f1af43436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: je fais ce cette , , , n ' est - ce pas ? ? ? - vo\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"I am doing great , WHat about you?\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbb0ee85-442a-4a6c-b716-60b44e0942c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: aujourd ' hui est un bon jour . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"Today's a good day.\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9141b069-f181-4020-af2b-09da36289d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: comment etait la ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"How was prison ?\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55df86d9-181f-4520-b800-706bab33aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: les la la ville . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "translation = predict_translation(model, \"Bite the bullet.\")\n",
    "print(f\"Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd041d-22f5-4e66-a5fe-4cb4c34dff46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
